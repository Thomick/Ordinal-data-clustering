q()
setwd("~/Google Drive/My Drive/Cours 3A/PGM/project/R_code")
install.packages("ordinalCloust", repos=NULL, type="source")
install.packages("./ordinalCloust", repos=NULL, type="source")
install.packages("./ordinalClost", repos=NULL, type="source")
install.packages("./ordinalClust", repos=NULL, type="source")
install.packages("./ordinalClust/", repos=NULL, type="source")
install.packages("Rcpp")
install.packages("Rcpp")
install.packages("RcppProgress")
install.packages("BH")
install.packages("RcppArmadillo")
install.packages("./ordinalClust/", repos=NULL, type="source")
install.packages("RcppArmadillo")
install.packages("RcppArmadillo")
warning: search path '/usr/local/gfortran/lib/gcc/x86_64-apple-darwin15/6.1.0' not found
unlink("~/.R/Makevars")
unlink("~/.Renviron")
file.edit("~/.Renviron")
install.packages("RcppArmadillo")
install.packages("./ordinalClust/", repos=NULL, type="source")
library(ordinalClust)
library(ordinalClust)
data("dataqol")
data("dataqol")
library(ordinalClust)
data("dataqol")
set.seed(1)
nbSEM <- 150
nbSEMburn <- 100
nbindmini <- 1
init <- "randomBurnin"
percentRandomB <- c(50, 50)
x <- as.matrix(dataqol.classif[, 2:29])
v <- as.vector(dataqol.classif$death)
nb.sample <- ceiling(nrow(x) *7/10)
sample.train <- sample(1:nrow(x), nb.sample, replace=FALSE)
x.train <- x[sample.train, ]
x.validation <- x[-sample.train, ]
v.train <- v[sample.train, ]
library(ordinalClust)
data("dataqol")
set.seed(1)
nbSEM <- 150
nbSEMburn <- 100
nbindmini <- 1
init <- "randomBurnin"
percentRandomB <- c(50, 50)
x <- as.matrix(dataqol.classif[, 2:29])
v <- as.vector(dataqol.classif$death)
nb.sample <- ceiling(nrow(x) *7/10)
sample.train <- sample(1:nrow(x), nb.sample, replace=FALSE)
x.train <- x[sample.train, ]
x.validation <- x[-sample.train, ]
v.train <- v[sample.train]
v.validation <- v[-sample.train]
kr <- 2
m <- 4
kcol <- c(0, 1, 2, 3, 4)
preds <- matrix(0, nrow=length(kcol), ncol=nrow(x.validation))
for( kc in 1:length(kcol) ){
classif <- bosclassif(x = x.train, y = v.train, kr = kr, kc = kcol[kc],
m = m, nbSEM = nbSEM, nbSEMburn = nbSEMburn,
nbindmini = nbindmini, init = init,
percentRandomB = percentRandomB)
new.prediction <- predict(classif, x.validation)
preds[kc,] <- new.prediction@zr_topredict
}
preds <- as.data.frame(preds)
row.names <- c()
for(kc in kcol){
name <- paste0("kc = ",kc)
row.names <- c(row.names,name)
}
rownames(preds)=row.names
preds
v.validation
bos_model <- function(n_cat, mu, pi) {
cur_e <- seq(1, n_cat)
for (i in seq_len(n_cat)) {
y <- sample(cur_e, i)
z <- rbinom(1, 1, pi)
e_minus <- cur_e[cur_e <y]
e_plus <- cur_e[cur_e > y]
e_equal <- cur_e[cur_e == y]
if (z == 0) {
p <- c(length(e_minus) / length(cur_e), length(e_plus) / length(cur_e), length(e_equal) / length(cur_e))
id <- sample(c(1, 2, 3), 1, prob = p)
cur_e <- list(e_minus, e_plus, e_equal)[[id]]
} else {
min_e <- e_equal
min_dist <- abs(mu - e_equal[1])
if (length(e_minus) != 0) {
d_e_minus <- min(abs(mu - e_minus[1]), abs(mu - e_minus[length(e_minus)]))
if (d_e_minus < min_dist) {
min_e <- e_minus
min_dist <- d_e_minus
}
}
if (length(e_plus) != 0) {
d_e_plus <- min(abs(mu - e_plus[1]), abs(mu - e_plus[length(e_plus)]))
if (d_e_plus < min_dist) {
min_e <- e_plus
}
}
cur_e <- min_e
}
if (length(cur_e) == 1) {
return(cur_e[1])
}
return(cur_e[1])
}
}
mu <- 2
pi <- 0.5
n_cat = 4
x <- bos_model(n_cat, mu, pi)
x <- bos_model(n_cat, mu, pi)
x
x <- bos_model(n_cat, mu, pi)
x
x <- bos_model(n_cat, mu, pi)
x
generate_data <- function(n, p, n_cat, k, alpha, mu, pi, seed) {
set.seed(seed)
w <- sample(1:k, n, replace=TRUE, alpha)
x <- matrix(0, nrow=n, ncol=p)
for (i in 1:n) {
for (j in 1:p) {
x[i, j] <- bos_model(n_cat[j], mu[[w[i]]][j], pi[[w[i]]][j])
}
}
return(list(x, w))
}
n <- 100
p <- 5
k <- 3
n_cat <- sample(2:5, p, replace=TRUE)
alpha <- runif(k)
alpha <- alpha/sum(alpha)
mu <- lapply(1:k, function(x) sample(1:10, p, replace=TRUE))
pi <- lapply(1:k, function(x) runif(p))
seed <- 12345
set.seed(seed)
x_synthethic <- generate_data(n, p, n_cat, k, alpha, mu, pi, seed)
x_synthetic
x_synthetic <- generate_data(n, p, n_cat, k, alpha, mu, pi, seed)
x_synthetic
output_synthetic_multivariate <- generate_data(n, p, n_cat, k, alpha, mu, pi, seed)
x_synthetic_multivariate <- output_synthetic_multivariate[1]
w_synthetic_multivariate <- output_synthetic_multivariate[2]
mu
k
n_cat
mu <- lapply(1:k, function(x) sample(1:k, p, replace=TRUE))
mu
mu <- lapply(1:k, function(x) sample(1:n_cat, p, replace=TRUE))
mu <- lapply(1:k, function(x) sapply(n_cat, function(nc) sample(1:nc, 1)))
mu
n_cat
output_synthetic_univariate <- generate_data(n, p, n_cat, k, alpha, mu, pi, seed)
x_synthetic_univariate <- output_synthetic_univariate[1]
w_synthetic_univariate <- output_synthetic_univariate[2]
x_synthetic_univariate
n <- 100
p <- 1
k <- 1
n_cat <- c(5)
alpha <- c(1)
mu <- lapply(1:k, function(x) sapply(n_cat, function(nc) sample(1:nc, 1)))
pi <- lapply(1:k, function(x) runif(p))
output_synthetic_univariate <- generate_data(n, p, n_cat, k, alpha, mu, pi, seed)
x_synthetic_univariate <- output_synthetic_univariate[1]
w_synthetic_univariate <- output_synthetic_univariate[2]
x_synthetic_univariate
plot(x_synthetic_univariate)
plot(x_synthetic_univariate[[,]])
plot(matrix(x_synthetic_univariate))
x_synthetic_univariate
x_synthetic_univariate[1]
x_synthetic_univariate[1,]
x_synthetic_univariate[[1]]
x_synthetic_univariate[[]]
x_synthetic_univariate[]
x_synthetic_univariate$1
matrix(x_synthetic_univariate)
list(x_synthetic_univariate)
c(x_synthetic_univariate)
library(gplots)
install.packages(gplots)
install.packages("gplots")
library(gplots)
data_matrix<- x_synthetic_univariate[[1]]
heatmap.2(data_matrix,
main = "Heatmap of Synthetic Data",
trace = "none",
Colv = NA,
Rowv = NA,
dendrogram = "none",
col = colorRampPalette(c("blue", "white", "red"))(256),
scale = "none")
data_matrix<- x_synthetic_univariate[[1]]
# Convert data matrix to a long format for ggplot
long_data <- reshape2::melt(data_matrix)
# Create a histogram for each feature
ggplot(long_data, aes(x = value)) +
geom_histogram(bins = 30, fill = "blue", color = "black") +
facet_wrap(~ variable, scales = "free") +
xlab("Value") +
ylab("Frequency") +
theme_minimal()
library(ggplot2)
library(ggplot)
library(tidyverse)
install.packages(tidyverse)
install.packages("tidyverse")
install.packages("tidyverse")
library(ggplot2)
data_matrix<- x_synthetic_univariate[[1]]
# Convert data matrix to a long format for ggplot
long_data <- reshape2::melt(data_matrix)
install.packages("reshape2")
# Convert data matrix to a long format for ggplot
long_data <- reshape2::melt(data_matrix)
# Create a histogram for each feature
ggplot(long_data, aes(x = value)) +
geom_histogram(bins = 30, fill = "blue", color = "black") +
facet_wrap(~ variable, scales = "free") +
xlab("Value") +
ylab("Frequency") +
theme_minimal()
