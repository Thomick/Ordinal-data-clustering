%\section{TODOs}
%\begin{itemize}
%    \item For the experiments:
%    \begin{itemize}
%        \item Test the robustness of the algorithm when facing outliers or skewed distributions.
%        \item Use noisy ordinal data (add discrete noise on a few features).
%        \item Test scalability of the algorithm (number of variables and data points).
%    \end{itemize}
%\end{itemize}

\section{Introduction}
The exploration of hidden structures within datasets is a crucial task for data scientists, and clustering serves as a valuable tool for this. Mixture models have emerged as a standard approach for clustering due to their capacity to provide a well-defined mathematical framework for parameter estimation and model selection. These models, instrumental in determining the number of clusters, not only encapsulate classical geometric methods but also find successful application in diverse practical scenarios.

In the realm of model-based clustering, the classification of data hinges on the availability of a suitable probability distribution tailored to the nature of the data at hand—be it numerical, rankings, functional, or categorical. Notably, ordinal data, where categories possess a specific order, represent a common occurrence, especially in fields like marketing where product evaluations are solicited through ordinal scales. Despite their prevalence, ordinal data have received comparatively less attention in the context of model-based clustering. Often, practitioners resort to transforming ordinal data into quantitative or nominal formats to align with readily applicable distributions, neglecting valuable order information.

This paper delves into the less-explored domain of model-based clustering for ordinal data, specifically focusing on ordinal data derived from sample surveys. Ordinal data find widespread application in fields such as social sciences, psychology, marketing, healthcare, and more. They enable researchers to capture nuanced information, such as preferences, attitudes, or severity levels, in cases where continuous measures are neither significant nor possible. For example, when assessing tumor severity, the precise size may not be as crucial as the current state of development of the disease as assessed by specialists. The use of ordinal data enriches the comprehension of subjective opinions, behaviors, and hierarchical relationships across diverse research contexts.

Multiple approaches have been proposed to model ordinal data. The first primary approach involves modeling a function of the cumulative probabilities of the ordinal categories as a linear function of some covariates. A comprehensive review of these models can be found in \cite{agresti2010analysis}. The second main approach involves modeling the ordinal categories as a function of a latent continuous variable, which is then linked to the ordinal categories through a link function. We assume that the ordinal observations are generated by a form of discretization of the latent continuous variable. An illustrative example of this approach is the ordered probit model, a generalization of the probit model for ordinal data.

A final approach that will particularly interest us in this paper is the use of a probabilistic model that directly captures the data-generating process for ordinal data, ensuring it exhibits desired properties. Two main models have been proposed in this category. The first and most studied one is the CUB model and its extensions \citep{d2005mixture}, which suggests modeling the data-generating process as a mixture of uniform and binomial distributions. Later, an additional Dirac distribution was introduced in the mixture, removing the dependence on the distance between categories imposed by the binomial distribution with the nonlinear CUB model \citep{manisera2014modeling}.
Another notable model in this category is the Binary Ordinal Search model, proposed by \cite{biernacki2016model}. This model posits that the observed data is the outcome of a stochastic process involving a binary search algorithm with corrupted comparisons. Parameterized with a position parameter (modal category) and a precision parameter, this model exhibits desirable properties similar to those of the CUB model. These properties include a unique mode, a probability distribution decrease on either side of the mode, and the flexibility to accommodate uniform or Dirac distributions.

In the context of clustering, a common approach is to use a mixture model for clustering the data. The mixture model is a probabilistic model that assumes the data is generated by a convex combination of several probability distributions. The clustering process then assigns each data point to the most likely distribution component given the data. In the case of the BOS model, maximum likelihood estimation using an EM algorithm can be employed, leveraging the latent variable interpretation of the binary search algorithm. While combinatorial complexity limits straightforward estimation for models based on latent Gaussian variables, the proposed approach remains tractable for ordinal data with up to eight categories—a common scenario for most ordinal variables. By contrast, the CUB model cannot be used for clustering in this way, as two CUB distributions cannot be distinguished from one another due to the uniform distribution component.


In this paper, we replicate and extend the findings of \cite{biernacki2016model}. We re-implemented their suggested probabilistic model, parameter estimation method, and model-based clustering algorithm in Python. Taking inspiration from their approach, we propose an alternative probabilistic model with similar properties. The aim is to address computational limitations, enabling the clustering of more extensive datasets with more categories than what the previous method allows. We also present an analysis of this new method to justify the decreased computational cost of estimating parameters for this model. Additionally, we test \cite{biernacki2016model}'s approach on real-world datasets and compare it to the proposed approach, along with baseline models. This is conducted on different datasets of multiple natures to check whether the proposed methods are successful in these practical settings and to identify their advantages. The ultimate goal is to assess whether the gains are significant against methods not adapted for ordinal datasets, deciding whether these approaches are interesting to use as a default method of choice for this type of variable.


