\subsubsection{Parameter estimation}

We want to estimate $\pi$ and $\mu$ from a sample $(1, \dots, m)$ with weights $W \in \RR_{+}^m$ generated by the GOD model. We aim at maximizing the likelihood of the sample : $\Pr(W | \pi, \mu)$. We proceed as explained in section~\ref{sec:univariate_generic_estimation}. All the proofs of this section are detailed in appendix~\ref{appendix:bos_proofs}, we only give here the main results.

\paragraph{Likelihood evaluation}

\begin{thm}[Likelihood is polynomial]
    $\forall m \in \NN^*, \forall x \in \bbrack{1, m}, \forall \mu \in \bbrack{1, m}$,:
    \[ \pi \mapsto \Pr(x | \mu, \pi) \]
    is a polynomial function of degree at most $m - 1$.  
\end{thm}

\begin{definition}
    We denote by $u[\mu, x, d]$ the coefficient of the polynomial of degree $d$ in the polynomial expansion of $\pi \mapsto \Pr(x | \mu, \pi)$ \textit{ie}:
    \[ \Pr(x | \mu, \pi) = \sum_{d = 0}^{m - 1} u[\mu, x, d] \pi^d \]
\end{definition}

We show that the likelihood of a single observation is a polynomial function of degree at most $m - 1$ in $\pi$. This result is important because, once the coefficients are known, it implies that the likelihood of a single observation can be computed in $\Theta(m)$ and the $\log$-likelihood of a sample (which has at most $m$ distinct values) in $\Theta(m^2)$ operations. 
For a fixed $m$, there is only $m^2$ polynomials to compute and store (one for each couple $(x, \mu)$), which leads to $m^3$ coefficients to store. We will show in the next paragraph~\ref{sec:bos_coefficients} that these coefficients can be computed in $\mathcal O(m^5)$ operations.

\paragraph{Computing the coefficients}
\label{sec:bos_coefficients}

\begin{definition}
    To simplify the comprehension of the following results, we introduce a notation for the probability in the case of $h$ categories~\footnote{This notation may seem different from the one used in the appendix but it is equivalent.}:
    \[ \bosl{x}{\mu}{h} := \Pr(x + 1 | \mu + 1, \pi) \text{ with }h\text{ categories}\]
\end{definition}

\begin{thm}[Computing the likelihood]
    \label{thm:computing_likelihood_bos}
    $\forall m \in \NN^*, \forall x \in \bbrack{1, m}, \forall \mu \in \bbrack{1, m}, \forall \pi \in [0, 1]$:

\begin{equation}
    \begin{aligned}
        \bosl{x}{\mu}{h}
        &=\frac{1}{h} \sum_{y = x + 1}^{h - 1} \bosl{x}{\mu}{y} \left[ \left( \indickronecker{\mu < y} - \frac{y}{h} \right) \pi + \frac{y}{h} \right] \\
            &+\frac{1}{h} \ \qquad \left[ \left( \indickronecker{\mu = x \lor (x = 0 \land \mu \leq x) \lor (x = h - 1 \land \mu \geq x)} - 1 \right) \pi +  \frac{1}{h} \right] \\
            &+\frac{1}{h} \sum_{y = 0}^{x - 1}\bosl{x - y}{\max(0, \mu - y)}{h - y}    \left[ \left( \indickronecker{\mu > y} - \frac{h - y - 1}{h} \right) \pi + \frac{h - y - 1}{h} \right]
    \end{aligned} \\
\end{equation}
\end{thm}

This theorem gives a recursive formula to compute the likelihood of a single observation. Using this formula, we can construct a dynamic programming algorithm to compute the coefficients of the polynomials. To do this we proceed by increasing $x$, $\mu$ and $h$. We do directly the multiplication of the polynomials.

Each term of the sum requires the multiplication of a polynomial of degree at most $m - 1$ by a polynomial of degree $2$ which gives a cost of $O(m)$. The sum has at most $m$ terms, which gives a cost of $O(m^2)$. We need to apply this formula for each $(x, \mu, h)$ which gives a cost of $O(m^5)$.

\paragraph{Log concavity}

\begin{conjecture}[Log concavity of the BOS model]
    $\forall m \in \NN^*, \forall x \in \bbrack{1, m}, \forall \mu \in \bbrack{1, m}$:
    \[\pi \mapsto \Pr(x | x, \mu, \pi) \] 
    is $\log$-concave on $[0, 1]$.
\end{conjecture}

As explained in section~\ref{sec:univariate_generic_estimation}, we directly have that $\forall \mu \in \bbrack{1, m}, \pi \mapsto L_W(\pi, \mu)$ is concave. Hence we can use a ternary search algorithm to estimate $\pi$ for a given $\mu$.

\paragraph{Method efficiency}

As presented in section~\ref{sec:univariate_generic_estimation}, we can estimate $\mu, \pi$ in $\mathcal O(m^3 \log \frac{1}{\epsilon})$ operations once the coefficients $u$ are computed. The coefficients $u$ can be computed in $\mathcal O(m^5)$ operations and stored in $\mathcal O(m^3)$ space. This is a major improvement compared to the EM algorithm proposed in~\cite{biernacki2016model}. Indeed we give a fully polynomial time algorithm with precision guarantees, while the EM algorithm has no guarantees on the precision and the proposed algorithm is exponential in the number of categories (a benchmark is given in section~\ref{sec:runtime}).




