\section{BOS Model proofs}
\label{appendix:bos_proofs}

\subsubsection{Notations}

\begin{definition}
    We define $\correct{\mu}{e}{y}{f}$ as the indicator function that $f$ is the correct subset to choose in case of a perfect comparison \textit{i.e.} if $\mu \in f$ or by default the closest to $\mu$.
\end{definition}

\begin{definition}
    We define $\nextes{e}{y}$ as the set of intervals that can be chosen after a comparison at breakpoint $y$ in the interval $e$ \textit{i.e.} $\nextes{e}{y} = \set{e^{-,y}, e^{=,y}, e^{+,y}}$ with $e = \bbrack{l, u - 1}$ and $y \in \bbrack{l, u - 1}$: $e^{-,y} = \bbrack{l, y - 1}$, $e^{=,y} = \set{y}$ and $e^{+,y} = \bbrack{y + 1, u - 1}$.
\end{definition}

We now suppose 
\begin{lemma}[$e_j$ transition]
    \label{lemma:bos_transition}
    $\forall m \in \NN^*, \forall x \in \bbrack{1, m}, \forall \mu \in \bbrack{1, m}, \pi \in [0, 1], \forall e \subset \bbrack{1, m}, \forall f \subset e$:
    \[ \Pr(f | x \in e, e, \mu, \pi) =  \frac{1}{\card{e}}  \sum_{y \in e} \left[ \left( \correct{\mu}{e}{y}{f} - \frac{\card{f}}{\card{e}} \right) \pi + \frac{\card{f}}{\card{e}} \right]  \indickronecker{x \in \nextes{e}{y}} \]

    Note that $\indickronecker{x \in \nextes{e}{y}} = 1$ only for one value of $y$ and $0$ for all the others. Moreover $\pi \mapsto \Pr(f | x \in e, e, \mu, \pi)$ is an affine function.
\end{lemma}
\begin{proof}
    We have that, by marginalization over the breakpoint $y$:
    \begin{align}
        \Pr(f | x \in e, e, \mu, \pi) 
        &= \sum_{y \in e} \Pr(f, y | x \in e, e, \mu, \pi) \\
        &= \sum_{y \in e} \Pr(f | y, x \in e, e, \mu, \pi) \Pr(y | x \in e, e, \mu, \pi) \\
        &= \sum_{y \in e} \Pr(f | y, x \in e, e, \mu, \pi) \frac{1}{\card{e}} \\
        &= \frac{1}{\card{e}} \sum_{y \in e} \Pr(f | y, x \in e, e, \mu, \pi)
    \end{align}

    Then by marginalization over the accuracy indicator $z$:
    \begin{align}
        \Pr(f | x \in e, e, \mu, \pi) 
        &= \frac{1}{\card{e}} \sum_{y \in e} \sum_{z \in \set{0, 1}} \Pr(f | y, x \in e, e, \mu, \pi, z) \Pr(z | y, x \in e, e, \mu, \pi) \\
        &= \frac{1}{\card{e}} \sum_{y \in e} \left[ \Pr(f | y, x \in e, e, \mu, \pi, z=1) \pi + \Pr(f | y, x \in e, e, \mu, \pi, z=0) (1 - \pi) \right] \\
        &= \frac{1}{\card{e}}  \sum_{y \in e} \left[ \correct{\mu}{e}{y}{f} \pi + \frac{\card{f}}{\card{e}} (1 - \pi) \right]  \indickronecker{x \in \nextes{e}{y}} \\
        &= \frac{1}{\card{e}}  \sum_{y \in e} \left[ \left( \correct{\mu}{e}{y}{f} - \frac{\card{f}}{\card{e}} \right) \pi + \frac{\card{f}}{\card{e}} \right]  \indickronecker{x \in \nextes{e}{y}}
    \end{align}
\end{proof}

\begin{lemma}
    \label{lemma:bos_polynomial}
    $\forall m \in \NN^*, \forall x \in \bbrack{1, m}, \forall \mu \in \bbrack{1, m}, \pi \in [0, 1], \forall e \subset \bbrack{1, m}$:
    \[ \pi \mapsto \Pr(x | x \in e, e, \mu, \pi)\] 
    is a polynomial function of degree at most $\card{e} - 1$.
\end{lemma}
\begin{proof}
    Let $m \in \NN^*, x \in \bbrack{1, m}, \mu \in \bbrack{1, m}, \pi \in [0, 1]$.

    We proceed by strong induction on $\card{e}$.
    \begin{itemize}
        \item Initialization: $\card{e} = 1$:
        \[ \Pr(x | x \in e, e, \mu, \pi) = \indickronecker{e = \set{x}} \] which is a polynomial function of degree $0$.
        
        \item Induction: Suppose the result holds for all $f \subset \bbrack{1, m}$ of size less or equal than $\card{e} - 1$ and let us prove it for $\card{e}$.
        
        We marginalize over the next interval $f$ and we have that:
        \begin{align}
            \Pr(x | x \in e, e, \mu, \pi) 
            &= \sum_{f \subset e} \Pr(x, f | x \in e, e, \mu, \pi) \\
            &= \sum_{f \subset e} \Pr(x | f, x \in e, e, \mu, \pi) \Pr(f | x \in e, e, \mu, \pi)
        \end{align}

        We can then notice that $\Pr(x | f, x \in e, e, \mu, \pi)$ is $0$ if $x \notin f$ and that $e$ does not intervene in the BOS process anymore. Hence we can replace $\Pr(x | f, x \in e, e, \mu, \pi)$ by $\Pr(x | x \in f, f, \mu, \pi)$ and sum only over $f \subset e$ such that $x \in f$:

        \begin{align}
            \Pr(x | x \in e, e, \mu, \pi) 
            &= \sum_{f \subset e ; x \in f} \Pr(x | x \in f, f, \mu, \pi) \Pr(f | x \in e, e, \mu, \pi)
        \end{align}

        As $\Pr(f | x \in e, e, \mu, \pi)$ is a polynomial function of degree at most $1$ (see lemma \ref{lemma:bos_transition}) and $\Pr(x | f, x \in f, f, \mu, \pi)$ is a polynomial function of degree at most $\card{f} - 1 \leq \card{e} - 2$ by induction hypothesis, we have that $\Pr(x | x \in e, e, \mu, \pi)$ is a polynomial function of degree at most $\card{e} - 1$.
    \end{itemize}

    Hence the result holds for all $e$.
\end{proof}


\begin{thm}[Likelihood is polynomial]
    \label{thm:likelihood_bos_is_polynomial}
    $\forall m \in \NN^*, \forall x \in \bbrack{1, m}, \forall \mu \in \bbrack{1, m}$,:
    \[ \pi \mapsto \Pr(x | \mu, \pi) \]
    is a polynomial function of degree at most $m - 1$.  
\end{thm}
\begin{proof}
    Let $m \in \NN^*$, $x \in \bbrack{1, m}$ and $\mu \in \bbrack{1, m}$. 

    First we can introduce redondant knowledge as we start necessarily with the full set of categories, we can add its value as known. We have that $\Pr(x | \mu, \pi) = \Pr(x | e_1, \mu, \pi)$. We also now that $x \in e_1$ therefore $\Pr(x | \mu, \pi) = \Pr(x | x \in e_1, e_1, \mu, \pi)$.

    We can now use the previous lemma~\ref{lemma:bos_polynomial} to conclude that $\Pr(x | \mu, \pi)$ is a polynomial function of degree at most $m - 1$.
\end{proof}


We can now prove that $\forall x \in \bbrack{0, h - 1}, \forall \mu \in \bbrack{0, h - 1}, \pi \mapsto \Pr(x | x \in \bbrack{0, h - 1}, \mu, \pi)$ is concave on $[0, 1]$


\begin{lemma}[Log concavity affine times polynomial]
    \label{lemma:concavity_log_polynomial_times_affine}
    For $I$ a real interval.

    Let $P$ be a $\log$-concave function on $I$ and $a, b \in \RR$ with $\forall t  \in I, at + b \geq 0$. Then $f: t \mapsto (at + b)P(t)$ is $\log$-concave on $I$.
\end{lemma}
\begin{proof}
    Let $t \in I$.

    As $at + b \geq 0$, we have that $f(t) \geq 0$. We can therefore consider its logarithm (with that $\log(0) = -\infty$).

    We have that:
    \begin{align}
        f'(t) &= aP(t) + (at + b)P'(t) \\
        f''(t) &= 2 aP'(t) + (at + b)P''(t) \\
        f'(t)^2 &= a^2P(t)^2 + 2a(at + b)P(t)P'(t) + (at + b)^2P'(t)^2 \\
        f(t)f''(t) &= 2a(at + b) P(t)P'(t) + (at + b)^2P(t)P''(t)
    \end{align}

    Hence:
    \[f'(t)^2 - f(t) f''(t) = a^2 P(t)^2 + (at + b)^2 \left[ P'(t)^2 - P(t)P''(t) \right] \]

    As $P$ is $\log$-concave on $I$, using the lemma~\ref{lemma:concavity_log_composed_functions} we have that $P'(t)^2 - P(t)P''(t) > 0$.
    
    As all the terms are $\geq 0$ we have that $\forall t \in I, f'(t)^2 - f(t) f''(t) \geq 0$ and using the lemma~\ref{lemma:concavity_log_composed_functions} we have that $f$ is $\log$-concave on $I$.
\end{proof}

\begin{lemma}[Log concavity of the BOS model]
    \label{lemma:log_concavity_bos_model}
    $\forall m \in \NN^*, \forall x \in \bbrack{1, m}, \forall \mu \in \bbrack{1, m},, \forall e \subset \bbrack{1, m}$:
    \[ \pi \mapsto \Pr(x | x \in e, e, \mu, \pi) \]
    is $\log$-concave on $[0, 1]$.
\end{lemma}
\begin{proof}
    Let $m \in \NN^*$, $x \in \bbrack{1, m}$ and $\mu \in \bbrack{1, m}$.
    We proceed by induction on $\card{e}$:

    \[ P_n : \forall e \subset \bbrack{1, m}, |e| \leq n \Rightarrow \pi \mapsto \Pr(x | x \in e, e, \mu, \pi) \text{ is } \log\text{-concave on } [0, 1] \]

    \begin{itemize}
        \item Initialization: $\card{e} = 1$:
        \[\pi \mapsto \Pr(x | x \in e, e, \mu, \pi) = \indickronecker{e = \set{x}} \] which is $\log$-concave on $[0, 1]$.
        Thus $P_1$ holds.

        \item Induction: Suppose $P_n$, the result holds for all $f \subset \bbrack{1, m}$ of size less or equal than $n$ and let us prove it for $n+1$.
        
        Let $e \subset \bbrack{1, m}$ such that $\card{e} = n + 1$.

        Using the lemma~\ref{lemma:bos_polynomial}, we have:
        \begin{align}
            \Pr(x | x \in e, e, \mu, \pi) 
            &= \sum_{f \subset e ; x \in f} \Pr(x | x \in f, f, \mu, \pi) \Pr(f | x \in e, e, \mu, \pi)
        \end{align}

        We have a sum of function. We now have to check that each function is $\log$-concave on $[0, 1]$. We will use the lemma~\ref{lemma:concavity_log_polynomial_times_affine}. 
        
        We first focus on $\Pr(f | x \in e, e, \mu, \pi)$.
        Using the lemma~\ref{lemma:bos_transition}, we have that  $\Pr(f | x \in e, e, \mu, \pi)$ is an affine function of $\pi$ and a probability therefore it is of the form $a \pi + b$ with $\forall \pi \in [0, 1], a \pi + b \geq 0$. 
        
        Using $P_n$ we have that $\pi \mapsto \Pr(x | x \in f, f, \mu, \pi)$ is $\log$-concave. Hence, using the lemma~\ref{lemma:concavity_log_polynomial_times_affine}, we have that each $\pi \mapsto \Pr(x | x \in f, f, \mu, \pi) \Pr(f | x \in e, e, \mu, \pi)$ is $\log$-concave on $[0, 1]$.
        
        This gives us that $\Pr(x | x \in e, e, \mu, \pi)$ is a sum of $\log$-concave functions and is therefore $\log$-concave on $[0, 1]$.

        This is true for any $e$ of size $n + 1$ and therefore $P_{n+1}$ holds.
        
    \end{itemize}

\end{proof}


\begin{thm}[Log concavity of the BOS model]
    $\forall m \in \NN^*, \forall x \in \bbrack{1, m}, \forall \mu \in \bbrack{1, m}$:
    \[\pi \mapsto \Pr(x | x, \mu, \pi) \] 
    is $\log$-concave on $[0, 1]$.
\end{thm}
\begin{proof}
    We just have to apply the lemma~\ref{lemma:log_concavity_bos_model} to the case where $e = \bbrack{1, m}$.
\end{proof}


\begin{lemma}[Symetries the likelihood]
    \label{lemma:symetries_bos}
    $\forall m \in \NN^*, \forall x \in \bbrack{1, m}, \forall \mu \in \bbrack{1, m}, \pi \in [0, 1], \forall e = \bbrack{l, u} \subset \bbrack{1, m}$:
    
    \[ \Pr(x | x \in \bbrack{l, u}, e = \bbrack{l, u}, \mu, \pi) = \Pr(x - l | x - l \in \bbrack{0, u - l}, e= \bbrack{0, u - l}, \max(0, \mu - l), \pi)\]
\end{lemma}
\begin{proof}
    \tr{To be done}
\end{proof}

\begin{definition}
    As justified by the lemma~\ref{lemma:symetries_bos}, we can define the following notation:
    \[ \bosl{x}{\mu}{h} := \Pr(x | x \in \bbrack{0, h - 1}, e = \bbrack{0, h - 1}, \mu, \pi) \]
\end{definition}

\begin{thm}[Computing the likelihood]
    \label{thm:computing_likelihood_bos}
    $\forall m \in \NN^*, \forall x \in \bbrack{1, m}, \forall \mu \in \bbrack{1, m}, \forall \pi \in [0, 1]$:

\begin{equation}
    \begin{aligned}
        \bosl{x}{\mu}{h}
        &=\frac{1}{h} \sum_{y = 0}^{x - 1} \bosl{x}{\mu}{y} \left[ \left( \indickronecker{\mu < y} - \frac{y}{h} \right) \pi + \frac{y}{h} \right] \\
        &+\frac{1}{h} \ \qquad \left[ \left( \indickronecker{\mu = x \lor (x = 0 \land \mu \leq x) \lor (x = h - 1 \land \mu \geq x)} - 1 \right) \pi +  \frac{1}{h} \right] \\
        &+\frac{1}{h} \sum_{y = x + 1}^{h - 1}\bosl{x - y}{\max(0, \mu - y)}{h - y}    \left[ \left( \indickronecker{\mu > y} - \frac{h - y - 1}{h} \right) \pi + \frac{h - y - 1}{h} \right]
    \end{aligned} \\
\end{equation}
\end{thm}

\begin{proof}

First we marginalize over the breakpoint $y$:
\begin{align}
    \bosl{x}{\mu}{h}
    &= \Pr(x | x \in \bbrack{0, h - 1}, e = \bbrack{0, h - 1}, \mu, \pi) \\
    &
    \begin{aligned}
        &= \sum_{y = 0}^{h - 1} \Pr(x, f=e^{-, y} | x \in \bbrack{0, h - 1}, e = \bbrack{0, h - 1}, \mu, \pi)\\
        &+ \sum_{y = 0}^{h - 1} \Pr(x, f=e^{=, y} | x \in \bbrack{0, h - 1}, e = \bbrack{0, h - 1}, \mu, \pi)\\
        &+ \sum_{y = 0}^{h - 1} \Pr(x, f=e^{+, y} | x \in \bbrack{0, h - 1}, e = \bbrack{0, h - 1}, \mu, \pi)
    \end{aligned} \\
\end{align}

Then we use the Bayes rule ($P(A, B) = P(A | B) P(B)$) to get likelihoods of $x$:

\begin{align}
    &
    \begin{aligned}
        &=\sum_{y = 0}^{h - 1} \Pr(x | x \in \bbrack{0, h - 1}, f = e^{-, y}, \mu, \pi) \Pr(e^{-, y} | x \in \bbrack{0, h - 1}, e = \bbrack{0, h - 1}, \mu, \pi)\\
        &+ \sum_{y = 0}^{h - 1} \Pr(x | x \in \bbrack{0, h - 1}, f = e^{=, y}, \mu, \pi) \Pr(e^{=, y} | x \in \bbrack{0, h - 1}, e = \bbrack{0, h - 1}, \mu, \pi)\\
        &+ \sum_{y = 0}^{h - 1} \Pr(x | x \in \bbrack{0, h - 1}, f = e^{+, y}, \mu, \pi) \Pr(e^{+, y} | x \in \bbrack{0, h - 1}, e = \bbrack{0, h - 1}, \mu, \pi)
    \end{aligned} \\
\end{align}

Then we can get rid of the case where $x \notin f$ as it is $0$: 
\begin{align}
    &
    \begin{aligned}
        &=\sum_{y = 0}^{x - 1} \Pr(x | x \in \bbrack{0, y - 1}, f = \bbrack{0, y - 1} , \mu, \pi) \Pr(\bbrack{0, y - 1} | x \in \bbrack{0, h - 1}, e = \bbrack{0, h - 1}, \mu, \pi)\\
        &+\ \qquad \Pr(x | x \in \set{x}, f = \set{x}, \mu, \pi) \Pr(\set{x} | x \in \bbrack{0, h - 1}, e = \bbrack{0, h - 1}, \mu, \pi)\\
        &+ \sum_{y = x + 1}^{h - 1} \Pr(x | x \in \bbrack{y + 1, h - 1}, f = \bbrack{y + 1, h - 1}, \mu, \pi) \\
        &\qquad \Pr(\bbrack{y + 1, h - 1} | x \in \bbrack{0, h - 1}, e = \bbrack{0, h - 1}, \mu, \pi)
    \end{aligned} \\
\end{align}

We can apply the lemma~\ref{lemma:symetries_bos} to the third term:
\begin{align}
    &
    \begin{aligned}
        &=\sum_{y = 0}^{x - 1} \Pr(x | x \in \bbrack{0, y - 1}, f = \bbrack{0, y - 1} , \mu, \pi) \Pr(\bbrack{0, y- 1} | x \in \bbrack{0, h - 1}, e = \bbrack{0, h - 1}, \mu, \pi)\\
        &+\ \qquad \Pr(x | x \in \set{x}, f = \set{x}, \mu, \pi) \Pr(\set{x} | x \in \bbrack{0, h - 1}, e = \bbrack{0, h - 1}, \mu, \pi)\\
        &+ \sum_{y = x + 1}^{h - 1} \Pr(x - y - 1 | x - y - 1\in \bbrack{0, h - 1 - y - 1}, f = \bbrack{0, h - 1 - y - 1}, \max(0, \mu - y - 1), \pi) \\
        &\qquad \Pr(\bbrack{y + 1, h - 1} | x \in \bbrack{0, h - 1}, e = \bbrack{0, h - 1}, \mu, \pi)
    \end{aligned} \\
    &
    \begin{aligned}
        &=\sum_{y = 0}^{x - 1} \bosl{x}{\mu}{y - 1} \Pr(\bbrack{0, y-1} | x \in \bbrack{0, h - 1}, e = \bbrack{0, h - 1}, \mu, \pi)\\
        &+\ \qquad \bosl{x}{\mu}{1} \Pr(\set{x} | x \in \bbrack{0, h - 1}, e = \bbrack{0, h - 1}, \mu, \pi)\\
        &+ \sum_{y = x + 1}^{h - 1}\bosl{x - y - 1}{\max(0, \mu - y - 1)}{h - y - 1} \Pr(\bbrack{y + 1, h - 1} | x \in \bbrack{0, h - 1}, e = \bbrack{0, h - 1}, \mu, \pi)
    \end{aligned} \\
\end{align}

First we have $\bosl{x}{\mu}{1} = 1$.
Moreover, we can now use the lemma~\ref{lemma:bos_transition} to get replace the transition probabilities. In our case as we already selected the only possible interval for each breakpoint we have the only term of the sum where $\indickronecker{x \in \nextes{e}{y}} = 1$ and the sum is reduced to a single term:

\begin{align}
    \begin{aligned}
        &=\sum_{y = 0}^{x - 1} \bosl{x}{\mu}{y - 1} \frac{1}{h} \left[ \left( \correct{\mu}{\bbrack{0, h - 1}}{y - 1}{\bbrack{0, y - 1}} - \frac{y}{h} \right) \pi + \frac{y}{h} \right] \\
        &+\ \qquad \frac{1}{h} \left[ \left(\correct{\mu}{\bbrack{0, h - 1}}{x}{\set{x}} - \frac{1}{h} \right) \pi + \frac{1}{h} \right] \\
        &+ \sum_{y = x + 1}^{h - 1}\bosl{x - y}{\max(0, \mu - y)}{h - y} \frac{1}{h}  \\
        &\qquad \left[ \left( \correct{\mu - y - 1}{\bbrack{0, h - 1 - y - 1}}{h - y - 1}{\bbrack{y, h - 1}} - \frac{h - y - 1}{h} \right) \pi + \frac{h - y - 1}{h} \right]
    \end{aligned} \\ 
\end{align}

We can then replace $\correct{\mu}{\bbrack{0, h - 1}}{\bullet}{\bullet}$ by a logical expression. (We must take into account the special case of the first and last breakpoint):

\begin{align}
    \begin{aligned}
        &=\frac{1}{h} \sum_{y = 0}^{x - 1} \bosl{x}{\mu}{y} \left[ \left( \indickronecker{\mu < y} - \frac{y}{h} \right) \pi + \frac{y}{h} \right] \\
        &+\frac{1}{h} \ \qquad \left[ \left( \indickronecker{\mu = x \lor (x = 0 \land \mu \leq x) \lor (x = h - 1 \land \mu \geq x)} - 1 \right) \pi +  \frac{1}{h} \right] \\
        &+\frac{1}{h} \sum_{y = x + 1}^{h - 1}\bosl{x - y}{\max(0, \mu - y)}{h - y}    \left[ \left( \indickronecker{\mu > y} - \frac{h - y - 1}{h} \right) \pi + \frac{h - y - 1}{h} \right]
    \end{aligned} \\
\end{align}
\end{proof}


% \begin{align}
%     \Pr(x | x \in e_j, \mu, \pi) 
%     &= \sum_{e_{j+1} \subset e_j} \Pr(x, e_{j+1} | x \in e_j, \mu, \pi) \\
%     &= \sum_{e_{j+1} \subset e_j} \Pr(x | e_{j+1}, x \in e_j, \mu, \pi) \Pr(e_{j+1} | e_j, \mu, \pi) \\
%     &= \sum_{e_{j+1} \subset e_j ; x\in e_{j+1}} \Pr(x | x \in e_{j+1}, \mu, \pi) \Pr(e_{j+1} | e_j, \mu, \pi)
% \end{align}
% 
% We now suppose $e_j = \bbrack{l, h - 1}$:
% 
% \begin{align}
%     &\Pr(x | x \in \bbrack{l, h-1}, \mu, \pi) =\\
%     &\begin{aligned}
%         &\sum_{y=x + 1}^{h-1} \Pr(\bbrack{l, y - 1} | \bbrack{l, h-1}, \mu, \pi) \Pr(x | x \in \bbrack{l, y - 1}, \mu, \pi) \\
%         &+ \Pr(\set{x} | \bbrack{l, h-1}, \mu, \pi) \Pr(x | x \in \set{x}, \mu, \pi) \\
%         &+ \sum_{y=l}^{x - 1} \Pr(\bbrack{y + 1, h-1} | \bbrack{l, h-1}, \mu, \pi) \Pr(x | x \in \bbrack{y + 1, h-1}, \mu, \pi)
%     \end{aligned} \\
%     &= \begin{aligned}
%         &\frac{1}{h - l} \sum_{y=x + 1}^{h-1} \left[ \pi \indickronecker{\mu < y} + (1-\pi) \frac{y - l}{h - l} \right] \Pr(x | x \in \bbrack{l, y - 1}, \mu, \pi) \\
%         &+\frac{1}{h - l} \left[ \pi \indickronecker{\mu = x \lor (x = l \land \mu \leq x) \lor (x = h - 1 \land \mu \geq x)} + (1 - \pi) \frac{1}{h-l} \right] \\
%         &\Pr(x | x \in \set{x}, \mu, \pi) \\
%         &+\frac{1}{h - l} \sum_{y=l}^{x - 1} \left[ \pi \indickronecker{\mu > y} + (1-\pi) \frac{h - y - 1}{h - l} \right] \Pr(x | x \in \bbrack{y + 1, h-1}, \mu, \pi)
%     \end{aligned}
% \end{align}
% 
% As $\Pr(x | x \in \set{x}, \mu, \pi) = 1$ this allows to compute the probability of $x$ being in the interval $\bbrack{l, h-1}$ recursively.
% 
% As:
% \begin{equation}
%     \Pr(x | x \in \bbrack{l, y - 1}, \mu, \pi) = \Pr(x - l | x - l \in \bbrack{0, y - l - 1}, \max(0, \mu - l), \pi)
% \end{equation}
% 
% We can rewrite the previous equation as:
% 
% \begin{align}
%     h\Pr(x | x \in \bbrack{0, h - 1})
%     &= \sum_{y = x + 1}^{h - 1} \left[ \pi \indickronecker{\mu < y} + (1-\pi) \frac{y}{h} \right] \Pr(x | x \in \bbrack{0, y - 1}, \mu, \pi) \\
%     &+ \pi \indickronecker{\mu = x \lor (x = 0 \land \mu \leq x) \lor (x = h - 1 \land \mu \geq x)} + (1 - \pi) \frac{1}{h} \\
%     &+ \sum_{y = 0}^{x - 1} \left[ \pi \indickronecker{\mu > y} + (1-\pi) \frac{h - y - 1}{h} \right] \Pr(x - y - 1 | x - y - 1 \in \bbrack{0, h - y - 2}, \max(0, \mu - y - 1), \pi)
% \end{align}
% 
% 

